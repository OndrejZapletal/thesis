* TODO Conclusion

  This thesis described brief history of Neural Networks, and its evolution into deep learning models. It highlighted differences of Convolutional and Fully Connected Neural Networks. Several examples of state of the art applications of Convolutional Neural Network were described.

  Practical experiments with Convolutional Neural Network models were proposed and. Proposed models were implemented using Keras library with support of Tensorflow. Training of implemented models was aided by parallel computing platform CUDA on Gforce GTX 1080 [[gls:gpu][GPU]].

# TODO: add actual numbers for top-1 and top-5 accuracy!!!
  Trained model was compared to latest results of [[gls:ilsvrc][ILSVRC]] competition. Somewhat surprisingly, best achieved top-1 accuracy of 0.6156 did not surpassed the AlexNet's top-1 accuracy of 0.625 on original [[gls:ilsvrc][ILSVRC]] dataset. This was surprising because reduced dataset had one-tenth of it's original classes. Possible explanation is that reduced dataset was too small and caused over-fitting of selected model.

  Future work would include expansion of selected dataset to full extend of [[gls:ilsvrc][ILSVRC]]. Another interesting avenue seems to be in non-conventional structure of Convolutional Neural Network. This includes inception modules from GoogLeNet or residual learning from Microsoft's ResNet.

  # Vision and hearing are still only very first steps on the journey towards general intelligence.

  # In the last section were described several possible frameworks for implementation of Deep learning and Convolutional Neural Network.

  # In the Master's Thesis that will be written in next semester is planned to implement Convolutional Neural Network in one of the discussed Deep Learning frameworks, and consequently compare this implementation with results of last year's ILSVRC contest [citation].

  # Keras was determined to be the best fit for the needs of this implementation and also keeping barriers to entry in lowest possible level.

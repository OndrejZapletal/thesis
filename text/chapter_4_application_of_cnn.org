
* Application of Convolutional Neural Networks
  # Sourced from http://machinelearningmastery.com/inspirational-applications-deep-learning/
  In this chapter will be described several application of [[gls:cnn][CNN]].
** Handwritten Digit recognition [citation]
   #+NAME: fig:mnist_100_digits
   #+CAPTION: Examples of 100 handwritten digits from MNIST dataset
   #+ATTR_LATEX: :width 4in
   [[./img/figure__4__mnist_100_digits.png]]
   As it was mentioned before convolutional neural networks were  originally designed for image processing applications. First mention of [[gls:cnn][CNN]] was in [LeCunn 1989] where they were used for recognition of handwritten digit from Dataset of Zip codes from US post. Concept was successfully deployed on DSP chip and tested in real-time application of sorting mail by the zip-code. [[gls:cnn][CNN]] were in this case one of the first models that was reaching human performance level. Similar techniques were later used to power automatic mail sorting in US Postal Service.

   # from http://machinelearningmastery.com/inspirational-applications-deep-learning/

**  Automatic colorization of black and white images [citation]
   # http://cs231n.stanford.edu/reports2016/219_Report.pdf
   #+NAME: fig:colorization
   #+CAPTION: Examples of automaticall colorated images
   #+ATTR_LATEX: :width 4in
   [[./img/figure__4__colorization.png]]

   Automatic colorization is interesting technical problem where the task is to create colored image from gray scale input. Any strides in automatization of this process are welcomed because until recently this was very tedious and slow process that needs to be heavily assisted by human. This task also seen some success  with regression based models, but resulting images wasn't very aesthetically pleasing.

   Application of very deep convolutional network managed to deliver very promising results.
   In this case convolution network was trained in supervised manner. As inputs were used gray scaled images that were trained to categorized detected shapes in gray-scale image to correct color. This technology could be also used to colorize black and white video.

** Automatically adding sounds to silent movies [citation]
   # https://arxiv.org/pdf/1512.08512.pdf

   #+NAME: fig:adding_sound
   #+CAPTION: Time line of automatically generated sound for silent video
   #+ATTR_LATEX: :width 4in
   [[./img/figure__4__adding_sound.png]]

   This is very interesting demonstration of capabilities of state of the art Deep Learning models. Solely based on silent video sequence of drumming stick hitting different surfaces with different textures, the model is capable to guess the sound effect that set hitting produces. Convolutional Neural Network was trained to classify the type of surface being hit from visual cues (vibration of hit surface, movement of particles upon impact and so on). And [[gls:lstm][LSTM]] Recurrent neural network was trained to reproduce sound patterns most similar to actual sound that was recorded in original video. Produced sounds were tested with human participants that had to distinguish synthesized sound from the real ones. Surprisingly in some cases the model fulled to test subjects.

** Automatic machine translation [citation]
   # http://www.nlpr.ia.ac.cn/cip/ZongPublications/2015/IEEE-Zhang-8-5.pdf
   #+NAME: fig:visual_translation
   #+CAPTION: Automatic vision translation on image in real time
   [[./img/figure__4__visual_translation.png]]
   Convolutional Neural Network was used to detected written text within image scenes and send to large [[gls:lstm][LSTM]] Recurrent neural network to provide translation. Translated text was then re-rendered back to original image converting foreign text into intelligible (translated). This application was deployed by Google in 2015 to their android devices as extension for Translator application. Feature was called instant visual translation.

** Automatic written description of scene in image [citation]
   # https://research.googleblog.com/2014/11/a-picture-is-worth-thousand-coherent.html
   #+NAME: fig:algorithm_for_image_description
   #+CAPTION: Structure of a learning algorithm used for automatic description
   #+ATTR_LATEX: :width 4in
   [[./img/figure__4__algorithm_for_image_description.png]]

   #+NAME: fig:scene_description
   #+CAPTION: Examples of scene description
   [[./img/figure__4__scene_description.png]]

   Already familiar combination of [[gls:cnn][CNN]] and [[gls:lstm][LSTM]] [[gls:rnn][RNN]] used in this case to describe scene depicted on image. [[gls:cnn][CNN]] was trained do categorize objects on image and [[gls:lstm][LSTM]] was to generate description of scene. It can be seen on image [] that the results are very impressive, even in cases that the model makes mistakes.

* Experiment
** Application
   In this chapter will be described several application of [[gls:cnn][CNN]].
*** Handwritten Digit recognition [citation]
    As it was mentioned before convolutional neural networks were  originally designed for image processing applications. First mention of [[gls:cnn][CNN]] was in [LeCunn 1989] where they were used for recognition of handwritten digit from Dataset of Zip codes from US post. Concept was successfully deployed on DSP chip and tested in real-time application of sorting mail by the zip-code. [[gls:cnn][CNN]] were in this case one of the first models that was reaching human performance level. Similar techniques were later used to power automatic mail sorting in US Postal Service.

    # from http://machinelearningmastery.com/inspirational-applications-deep-learning/

***  Automatic colorization of black and white images [citation]
 # http://cs231n.stanford.edu/reports2016/219_Report.pdf
    Automatic colorization is interesting technical problem where the task is to create colored image from gray scale input. Any strides in automatization of this process are welcomed because until recently this was very tedious and slow process that needs to be heavily assisted by human. This task also seen some success  with regression based models, but resulting images wasn't very aesthetically pleasing.

    Application of very deep convolutional network managed to deliver very promising results.
    In this case convolution network was trained in supervised manner. As inputs were used gray scaled images that were trained to categorized detected shapes in gray-scale image to correct color. This technology could be also used to colorize black and white video.

*** Automatically adding sounds to silent movies [citation]
 # https://arxiv.org/pdf/1512.08512.pdf

 This is very interesting demonstration of capabilities of state of the art Deep Learning models. Solely based on silent video sequence of drumming stick hitting different surfaces with different textures, the model is capable to guess the sound effect that set hitting produces. Convolutional Neural Network was trained to classify the type of surface being hit from visual cues (vibration of hit surface, movement of particles upon impact and so on). And [[gls:lstm][LSTM]] Recurrent neural network was trained to reproduce sound patterns most similar to actual sound that was recorded in original video. Produced sounds were tested with human participants that had to distinguish synthesized sound from the real ones. Surprisingly in some cases the model fulled to test subjects.

*** Automatic machine translation [citation]
 # http://www.nlpr.ia.ac.cn/cip/ZongPublications/2015/IEEE-Zhang-8-5.pdf

 Convolutional Neural Network was used to detected written text within image scenes and send to large [[gls:lstm][LSTM]] Recurrent neural network to provide translation. Translated text was then re-rendered back to original image converting foreign text into intelligible (translated). This application was deployed by Google in 2015 to their android devices as extension for Translator application. Feature was called instant visual translation.

*** Automatic written description of scene in image [citation]
 # https://arxiv.org/pdf/1411.4389v4.pdf

 Already familiar combination of [[gls:cnn][CNN]] and [[gls:lstm][LSTM]] [[gls:rnn][RNN]] used in this case to describe scene depicted on image. [[gls:cnn][CNN]] was trained do categorize objects on image and [[gls:lstm][LSTM]] was to generate description of scene. It can be seen on image [] that the results are very impressive, even in cases that the model makes mistakes.
# 6 Frameworks

** Frameworks
   There is wide variety of options for machine learning frameworks in general and also for [[gls:cnn][CNN]] specifically. Namely there is a variety of tools that are centered around python programming language. All of the frameworks mentioned bellow have at least some support for GPGPU computation.

*** Caffe
   - Deep learning framework implemented in C++ programming language, that also supports python API.
   - It was difficult to find any good documentation and in terms of popularity it was not so prominent as some other frameworks in this list.

*** Keras
   - Kears is implemented in python and therefore integrates well with the massive Data Science ecosystem that Python is offering. It probably currently has one of the largest communities in deep learning. It has most monthly mentions in Arxiv database, in scientific papers dealing with deep learning.
   - Keras has very good documentation, many code examples and other resources that help users to get started very quickly.
   - It can run on top of both TensorFlow and Theano engines. Specifically in the case of TensorFlow this is very good news since it is developed by Google, which is dividing enormous amount of resources to make sure that it is one of the (or maybe even the one) fastest deep learning engines out there.
   - Keras is supported by CUDA (cuDNN) which is very important specifically for [[gls:cnn][CNN]] models with usage of GPU hardware.
*** MatConvNet
   - Matlab toolbox implementing CNNs for computer vision application.
   - It has the disadvantage of being part of proprietary software
   - Its community is not nearly as big as in case of Torch or Keras

*** Scikit learn
   - is also python framework that is very popular and offers wide variety of machine learning models but it is not so versatile and it is obvious that is more geared towards hobbyist then for scientific community.
   - The support for Deep Learning is not as wide as it is for example at Keras

*** Torch
   - Scientific computing framework with support of wide variety of machine learning algorithms.
   - Torch was one of the first universal and modular frameworks developed specifically for the needs of Deep learning. It was very prominent few years ago, but it seems that it lost some traction and is not as prevalent as it once was. One of the possible reasons for this might be that it is implemented in Lua programming language that is not nearly so popular as for example python.
** Design of experiment
   There are three standard benchmark datasets used when it comes [[gls:deep learning][deep learning]]. MNIST, CIFAR and ILSVRC.
Accuracy of several models on training data.

\begin{tikzpicture}
  \begin{axis}[
      title={Accuracy on training data},
      xlabel={epoch},
      ylabel={accuracy [\%]},
      ymin=0, ymax=1,
      ytick={0.2,0.4,0.6,0.8,1},
      legend pos=south east,
      ymajorgrids=true,
      xmajorgrids=true,
      grid style=dashed,
      scale=1.5,
  ]

  \addplot[color=blue]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_1_13422B12_adam_performance.log};
      \addlegendentry{Model 1}
  \addplot[color=red]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_2_13422B12_adam_performance.log};
      \addlegendentry{Model 2}
  \addplot[color=green]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_3_13422B12_adam_performance.log};
      \addlegendentry{Model 3}
  \addplot[color=brown]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_4_B536FE0E_adam_performance.log};
      \addlegendentry{Model 4}
  \addplot[color=yellow]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_5_F6309B1C_adam_performance.log};
      \addlegendentry{Model 5}
  \addplot[color=purple]
      table [x=epoch, y=acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_6_2CD19B7B_adam_performance.log};
      \addlegendentry{Model 6}

  \end{axis}
\end{tikzpicture}

Accuracy of several models on testing data.

\begin{tikzpicture}
  \begin{axis}[
      title={Accuracy on testing data},
      xlabel={epoch},
      ylabel={accuracy [\%]},
      ymin=0.3, ymax=0.9,
      ytick={0.4,0.6,0.8},
      legend pos=south east,
      ymajorgrids=true,
      xmajorgrids=true,
      grid style=dashed,
      scale=1.5,
  ]

  \addplot[color=blue]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_1_13422B12_adam_performance.log};
      \addlegendentry{Model 1}
  \addplot[color=red]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_2_13422B12_adam_performance.log};
      \addlegendentry{Model 2}
  \addplot[color=green]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_3_13422B12_adam_performance.log};
      \addlegendentry{Model 3}
  \addplot[color=brown]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_4_B536FE0E_adam_performance.log};
      \addlegendentry{Model 4}
  \addplot[color=yellow]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_5_F6309B1C_adam_performance.log};
      \addlegendentry{Model 5}
  \addplot[color=purple]
      table [x=epoch, y=val_acc, col sep=comma]
      {/home/derekin/Dropbox/trained_models/model_6_2CD19B7B_adam_performance.log};
      \addlegendentry{Model 6}

  \end{axis}
\end{tikzpicture}
*** Comparison of depth of classification portion
 \begin{tikzpicture}
   \begin{axis}[
       title={Accuracy on training data},
       xlabel={epoch},
       ylabel={accuracy [\%]},
       ymin=0, ymax=1,
       ytick={0.2,0.4,0.6,0.8,1},
       legend pos=south east,
       ymajorgrids=true,
       xmajorgrids=true,
       grid style=dashed,
       scale=1.5,
   ]

   \addplot[color=blue]
       table [x=epoch, y=acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_1_adam_performance.log};
       \addlegendentry{Model 1}
   \addplot[color=red]
       table [x=epoch, y=acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_2_adam_performance.log};
       \addlegendentry{Model 2}
   \addplot[color=green]
       table [x=epoch, y=acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_3_adam_performance.log};
       \addlegendentry{Model 3}

   \end{axis}
 \end{tikzpicture}

 \begin{tikzpicture}
   \begin{axis}[
       title={Accuracy on testing data},
       xlabel={epoch},
       ylabel={accuracy [\%]},
       ymin=0.3, ymax=0.9,
       ytick={0.4,0.6,0.8},
       legend pos=south east,
       ymajorgrids=true,
       xmajorgrids=true,
       grid style=dashed,
       scale=1.5,
   ]

   \addplot[color=blue]
       table [x=epoch, y=val_acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_1_adam_performance.log};
       \addlegendentry{Model 1}
   \addplot[color=red]
       table [x=epoch, y=val_acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_2_adam_performance.log};
       \addlegendentry{Model 2}
   \addplot[color=green]
       table [x=epoch, y=val_acc, col sep=comma]
       {/home/derekin/Dropbox/trained_models/model_test_of_fully_connected_3_adam_performance.log};
       \addlegendentry{Model 3}

   \end{axis}
 \end{tikzpicture}

* TODO Proposed Experimental Concept
  This chapter is focused on description of proposed experiment. In the beginning are described available software tools. Following that, is description of software and hardware configuration of testing equipment. Next the preparation of ImageNet dataset is described. The last portion of this chapter is dedicated to specifics of implementation.

** Software Tools
   In order to select appropriate tool for implementation of [[gls:cnn][CNN]] for [[gls:ilsvrc][ILSVRC]] classification, investigation of available software tools and libraries was conducted. There is vast variety of software tools for machine learning. Some of these are general tools for machine learning, but some are specifically designed for [[gls:deep learning][deep learning]].

   In the last 10, years the software tools for machine learning has undergone a renaissance. There is broad selection of them available and new tools are introduced quite frequently. For example Caffe2[fn:1] was introduced very recently on April 18^th. Almost every commonly used programming language has either some software library or at least some available [[gls:api][API]].

   # TODO: this need some polishing
   The selection of the software tool was influenced by several factors. Firstly the implementing language had to be well know and somewhat mainstream. Enough of available learning materials had to be available, preferably in form of tutorials. The most important factor was good support for learning on [[gls:gpu][GPU]].

[fn:1] Newer version of popular Caffe framework now available at \url{https://caffe2.ai/}.
**** Theano
     It is seasoned python library. Designed to define, optimize and evaluate mathematical expression with multi-dimensional arrays. This makes it suitable for machine learning needs. Theano is built on top of Numpy, which is python module that enables efficient operation with tensors and basic image processing technique. Combination of Numpy and Scipy brings rich set of tools for image processing and data processing. Its capabilities can arguably rival MatLab, while being open source and free.

     Theano's biggest rival is currently Tensorflow project. One of the problems of Theano is its low level nature. Implementation of machine learning algorithms directly can be very complicated. This is probably the reason it slowly falling by the way side. This is also the reason why Theano as a tool is not very suitable for direct implementation of [[gls:cnn][CNN]] models.

**** Torch
     Torch is one of the oldest frameworks for scientific computing. It is rich and powerful tool that was one the first heavily used for deep learning applications. Similarly to other items in this list it offers fast and efficient [[gls:gpu][GPU]] support.

     Minor negative of Torch is that it uses Lua scripting language as a programming interface. Lua is not very commonly used and as such it suffers from lack of interest of the mainstream machine learning community.


**** TODO Tensorflow
     Tensorflow is very similar to Theano. As the name suggest this library is focused on effective work with tensors. It was originally developed for internal use in Google for machine learning task but it was released as open source in 2015.
     Tensofrlow computations are expressed as stateful dataflow graphs, which enables efficient support for [[gls:gpu][GPU]] aided computation. Is currently advertised as one of the fastest frameworks for deep learning needs.

     Its disadvantage is similar to Theano, in the fact that it is very low level and direct usage for implementation of Deep learning models is not ideal.

**** Caffe
     Caffe is a deep learning framework that aims to be modular and fast. It is developed by Berkeley AI Research (BAIR) and by community contributors. Yangqing Jia created the project during his PhD at UC Berkeley. It is implemented in C++ but it also offers [[glspl:api][API]] for several other languages as for example python.

     Its biggest drawback is its lack of quality documentation. This fact is partially remedied by the existence of Model Zoo, which is collection of favorite models that are freely available. Caffe was in the last years used by companies as Facebook for example mainly because its performance capabilities. Caffe is more geared towards the development of mass production application than it is for research purposes.

**** Keras
     Keras is relatively young but mature project written in python. It is high lever neural network [[gls:api][API]]. It is build capable of running on top of either Theano or Tensorflow libraries. It is very simple with emphasis on rapid model development. At the same time thanks to python infrastructure it is very easily extensible.

     Keras probably currently has one of the largest communities among similar tools for deep learning. It has very good documentation containing many code examples and other resources that help users to get started very quickly.

     Since both Theano and Tensorflow support execution models on [[gls:gpu][GPU]] units it extends this possibility to Keras as well.

** Hardware and Software Configuration
   Training of [[gls:nn][NN]] is notoriously computational expensive and it demands a lot of resources. From low level perspective it translates into many multiplications of matrices. Modern [[glspl:cpu][CPU]] are not optimized for such computations and therefore are not very good at it. On the other hand, modern [[glspl:gpu][GPU]] are designed to preform precisely these operations.

   Currently on the market there are two major parallel computing platforms CUDA and OpenCL. They both have pros and cons but the major difference is that CUDA is proprietary, while OpenCL is open source. This divide translates into hardware manufactures as well. CUDA is mainly supported by Nvida and OpenCL is support by AMD. Nvidia with its CUDA platform is currently leader in the domain of deep learning. Therefore, for training of [[gls:cnn][CNN]] models was was selected [[gls:gpu][GPU]] from Nvidia. Selected model was GIGABYTE GeForce GTX 1080. Summary of relevant available hardware configuration is in Table [[tab:hardware_configuration]].

   #+NAME: tab:hardware_configuration
   #+CAPTION: Hardware configuration
   #+ATTR_LATEX: :align | l | l | :font \scriptsize
   |--------+-----------------------------------------|
   | GPU    | GeForce GTX 1080 8GB                    |
   |--------+-----------------------------------------|
   | CPU    | Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz |
   |--------+-----------------------------------------|
   | Memory | DIMM 1333MHz 8GB                        |
   |--------+-----------------------------------------|

   From the list of considered software libraries was selected Keras. The reason being that Keras fulfilled all consideration factors and because it was written in python which was most familiar to the author. Support of efficient [[gls:gpu][GPU]] in Keras is relying on either Theano or Tensorflow back-end. From the user perspective it doesn't really mater either way, but Tensorflow was selected because it was regarded as faster of the two. Latest supported version of CUDA platform was 7.5. and PC was also equipped with cuDNN v5.1, which is GPU-accelerated library of primitives for deep neural networks. Details of software configuration is summarized in table [[tab:software_configuration]].

   #+NAME: tab:software_configuration
   #+CAPTION: Software configuration
   #+ATTR_LATEX: :align | l | l | :font \scriptsize
   |-------------+-------|
   | Keras       |  2.04 |
   |-------------+-------|
   | Tensorflow  | 1.1.0 |
   |-------------+-------|
   | CUDA        |   7.5 |
   |-------------+-------|
   | cuDNN       |   5.1 |
   |-------------+-------|
   | Python      |  3.53 |
   |-------------+-------|
   | Ubuntu Mate | 17.04 |
   |-------------+-------|

** Dataset Preparation

   Due to a organizational difficulties it took a long time to obtain viable hardware that could have been used for training of the network. It was decided that instead of regular [[gls:ilsvrc][ILSVRC]] challenge, this thesis will attempted to solve reduced version of the task. This reduction involves number of classes. From original [[gls:ilsvrc][ILSVRC]] dataset was randomly selected 100 classes. This seamed to be a reasonable compromise to preserve some of the inert difficulty of the problem while meeting the deadline of this thesis. This reduction necessarily influences the predictive value of performed experiment. One of its effects is reduction of the fine-grained recognition present in original dataset. This is due to a fact that original  ImageNet dataset contains 120 categories of different breeds of dogs.

   # When considering impact of this decision the first conclusion is obvious tests of

   # First consideration is whether the reduction didn't change the difficulty significantly.

   Even after the reduction, one of the biggest challenges of the ImageNet dataset, was its size. Typical benchmark datasets for [[gls:nn][NN]] applications, MNIST or CIFAR10 are much smaller in comparison. It is feasible to work with them within memory. In case of ImageNet dataset, any augmentation of the dataset that required to load it into memory had to fail[fn:2].

   Therefore any data preparation had to be performed in batches. Python ecosystem offers several options for storing of data for mathematical manipulation. For these specific requirements was selected \acrshort{hdf5}[fn:3] binary data format. Image data were saved into hard-drive using h5py python library.

   Images contained in the dataset are quite varied. They have different number of pixels, aspect ratio and overall quality. Selected model imposed the constraint that each image has to be of the same size and aspect ratio. Selected size of the images was 256x256 pixels, based on the work described in \cite{article--krizhevsky--2012}. Dataset preparation was done in three stages.


[fn:2]Reason behind this is that roughly 50000 images in resolution $255 \times 255 \times 3$ in Float32 format requires 36.1 GBytes of memory.
[fn:3] \url{https://support.hdfgroup.org/HDF5/}

**** Image Pre-processing
     In the first stage was randomly selected 100 categories. Every image from this subset was pre-processed in following way. When both sides of the image were larger than 256 pixels, it was re-sized so that the shorter side matched the 256 pixels and exceeding pixels on the longer side were cropped out.
     Every image that had one side larger and smaller was filled by zeros on the shorter side and cropped on the longer side. In case that both sides were shorter then 256 pixels it was re-sized in similar way as in case of both sides larger but the size of image was increased instead of decreased.

**** Split Data into Training a Testing Dataset
     <<data-preparation>>
     In the [[gls:ilsvrc][ILSVRC]] competition the participants are provided with special validation and testing instances, in this setup the training images were split into two datasets instead. This was done only because it saved time during crucial time period of designing the experiments. This decision has a drawback because it necessarily reduces the amount of data available for training of the network. But since the dataset was substantially smaller then in [[gls:ilsvrc][ILSVRC]] competition it didn't represent a big problem. Ratio of train to test size was selected 9:1. Training dataset contained 44323 images and testing dataset contained 4925 images.

     It was made sure that images are randomly split between test and train dataset so that both dataset have roughly equal split among the categories. It is very important that the model is trained with alternating categories. For example if the model would be exposed to images of the same category in the row the update of weights of in the given cycle would be biased to this category. In other words it would be over fitted, which is not desirable.

     It was found that simple random selection of images didn't vouch for equally representation in resulting datasets. This was caused by the fact that not all classes had the same number of training images. Average number of images was around 500 per class, but some classes had over 1000 images. It was solved by intervention on every third draw during random selection. In this intervention was selected the category that currently had most images left.

**** Format Conversion
     In the last stage were images normalized and converted to appropriate data type. Original images were [[gls:rgb][RGB]] with individual pixels coded as Unit8 type with values in range 0-255. Keras model requires data to be provided in float32 type. Therefore the pre-processed images had to be converted. It was also normalized into range 0-1. To normalize each pixel was simply divided by maximal value of uint8, which is 255.

     Data with correct label for the images were integers with index in range 0-100. Keras model expects the label data in categorical format. Categorical format converts each index of the label data into vector of all zeroes but one of length equal to number of categories. Element of the vector with index equal to original index of the labeled data is equal to one.

     To convert a instance into categorical format following function was used
     #+BEGIN_SRC python
     np_utils.to_categorical(y, num_classes)
     #+END_SRC
     This function is available in =keras.utils= module.

     For illustration in dataset with 5 classes an instance of class label with index 3
     #+BEGIN_SRC python
     >>> y_instance
     3
     >>> np_utils.to_categorical(y_instance, 5)
     [0.0, 0.0, 0.0, 1.0, 0.0]
     #+END_SRC

     Both of these operation needed to be performed on each instance of the data and since this couldn't be done in memory, the whole process was executed in batches of 500 images.
     #+BEGIN_SRC python
     # X_train Y_train datasets are devided into batches of 500
     for index in range(0, len(X_train), 500):
         index_end = index + 500

         # normalize values
         X_train[index:index_end] = np.divide(
             X_train[index:index_end], 255)

         # convert to categorical
         Y_train[index:index_end] = np_utils.to_categorical(
             Y_train[index:index_end], 100)
     #+END_SRC

** Data Augmentation
    Main problem with ImageNet dataset is that it has relatively few images per category. This issue was exacerbated by the decision to also use train dataset for testing purposes described in section [[data-preparation]]. Data augmentation procedure suggested in \cite{article--krizhevsky--2012} was performed to combat this. During training of the network each image was augmented before it was fed into the network. Pre-processed images from \acrshort{hdf5} file have size $256 \times 256 \times 3$ pixels. While the size of input of the [[gls:cnn][CNN]] is setup to process data of size $224 \times 224 \times 3$. Therefore each image that is send on the net's input was randomly generated patch of size $224 \times 224 \times 3$ from the pre-processed image. The generated patch was also flipped horizontally With probability of 0.5. By this augmentation the training dataset is theoretically extended by factor of 2048[fn:4]. Example of the this process is depicted on figure [[fig:data_augmentation]]


    #+NAME: fig:data_augmentation
    #+CAPTION: Original image (left up). Downsized and cropped on the sides (right up). Six randomly generated patches from processed image (bottom).
    #+ATTR_LATEX: :heigth 2in
    [[./img/figure__4__data_augmentation.jpg]]

[fn:4] /(size of an image side - size of generated patch)^2 * horizontal flip/ $[(256 - 224)^2 \times 2 = 2048]$.

** Model Building Blocks
   For implementation of [[gls:cnn][CNN]] was used Keras sequential model, which is a concept that is appropriate for modeling of feed forward network. Definition of the network is composed of layers. Concept of layer in Keras sequential model doesn't completely map into already described definition of layer from topological perspective. Keras layers are more fine grained and in order to create equivalent topological layer it is necessary to use multiple Keras layers.

   Model is created simply by calling =Sequential= constructor
   #+BEGIN_SRC python
   model = Sequential().
   #+END_SRC

   Layers are added by calling an =add= method on object of sequential model
   #+BEGIN_SRC python
   model.add(layer),
    #+END_SRC
   where =layer= is definition of the layer.

*** Keras Layers
    All models were created by composition of following layers.

**** Convolutional
     Convolutional layer used in the architecture was of following structure
     #+BEGIN_SRC python
     Conv2D(filters=n, kernel_size=(z, z), strides=(s, s), padding='valid',
            input_shape=shape)
     #+END_SRC
     where =n= is number of filters that the layer will have, $z$ is size of kernel, $s$ is number of pixels in stride and =input_shape= defines size of input matrix.

**** Activation
     To add activation function on the output of the layer user can specify parameter =activation= of the layer itself or create activation as a layer
     #+BEGIN_SRC python
     Activation(acitvation_function)
     #+END_SRC
     where =activation_function= is either 'softmax' or 'relu'. Both specifications are equivalent because Keras automatically uses linear activation function for each layer.

**** Pooling
     Pooling layer can be specified as
     #+BEGIN_SRC python
     MaxPooling2D(pool_size=(z, z), strides=(s, s))
     #+END_SRC
     where =pool_size= specifies size of pooling kernel and =strides= specifies number of pixels in x and y direction that are traversed in between application of individual pools.

**** Fully Connected
     Fully connected layer is created by
     #+BEGIN_SRC python
     Dense(num_of_units)
     #+END_SRC
     where =num_of_units= is a number of fully connected neurons in one layer.

**** Dropout
     Similarly to activation function to apply a dropout regularization on a layer it needs to be added after it as another layer.
     #+BEGIN_SRC python
     Dropout(p)
     #+END_SRC
     where =p= is both probability that any unit is dropped and also the coefficient by which are the outputs multiplied during forward evaluation.

**** Other
     Feature extraction layers are multidimensional. Specifically both Convolutional and Pooling layers are two dimensional. Classification layers that are created by fully connected layers are one dimensional. To connect the two, it is necessary to create mapping between them. For this purposes it necessary to use following layer
     #+BEGIN_SRC python
     Flatten()
     #+END_SRC
     which takes care of necessary connections between layers.

*** Model Compilation
    When the structure of the model is specified, before it can be trained it also needs to have cost function, optimization procedure and metrics defined. This is done be calling =compile= method on the model
    #+BEGIN_SRC python
    model.compile(
        loss= 'categorical_crossentropy',
        optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999,
                       epsilon=1e-08, decay=0.0),
        metrics=['accuracy'])
    #+END_SRC
    parameter =loss= specifies cost function, =optimizer= optimization procedure and =metrics= specifies metrics by which the model is measured.

*** Model Fitting
    Process of model training is in Keras called model fitting. It offers two types of fitting methods =fit= and =fit_generator=. Method =fit= loads entire dataset at once and use it train the network. For reasons laid out earlier this not possible with ImageNet dataset. Second option =fit_generator= method uses feature of python language called generator[fn:5].

    Generator =generate_data= was implemented to supply data from ImageNet dataset.
    #+BEGIN_SRC python
      def generate_data(hdf5_file_name, batch_size, data_type):
          """Generator that is providing data from dataset in
          infinite loop.
          """
          with h5py.File(hf5_file_name, 'r') as hf5:
              data_x = hf5["/data/%s/x" % data_type]
              data_y = hf5["/data/%s/y" % data_type]
              pos = 0
              size = data_x.shape[0]

              # infinite loop
              while True:
                  if pos + step <= size:
                      batch_x = data_x[pos:pos + step]
                      batch_y = data_y[pos:pos + step]
                  else:
                      temp = pos
                      pos = (pos + step) - size
                      batch_x = np.concatenate(
                          (data_x[0:pos], data_x[temp:size]))
                      batch_y = np.concatenate(
                          (data_y[0:pos], data_y[temp:size]))

                  pos += step

                  augmented_batch_x = np.empty((step, 224, 224, 3))
                  for index, image in enumerate(batch_x):
                      if data_type == "train":
                          augmented_batch_x[index] = \
                              generate_random_patch(image)
                      elif data_type == "test":
                          augmented_batch_x[index] = \
                              get_center_patch(image)

                  yield (augmented_batch_x, batch_y)
    #+END_SRC

    This generator is generating data from HDF5 file in infinite loop. Depending on the parameter =data_type= it ether generates training or testing data. Difference between the two is that testing data are generated as center patch of size 224x224x3 from the original sized image 256x256x3. Training data are generated as patch of size 224x224x3 from random position. Parameter =batch_size= determines size of generated batch.

    Very useful property of fit =fit_generator= method is that while the model is trained on [[gls:gpu][GPU]] it is able to prepare another batches of training data in parallel. This is very useful because the data augmentation performed by the generator does not slow down the training process.


    #+BEGIN_SRC python
    model.fit_generator(
        generator=generate_data(HDF5_FILE_NAME,
                                train_batch_size,
                                "train"),
        steps_per_epoch=steps_per_epoch,
        epochs=epochs,
        verbose=1,
        validation_data=generate_data(HDF5_FILE_NAME,
                                      test_batch_size,
                                      "test"),
        validation_steps=validation_steps,
        max_q_size=10,
        workers=4,
        pickle_safe=True)
    #+END_SRC

    Method =fit_generator= has been used to train model with following parameters:
    - =generator= : initialized with =generate_data= for training data.
    - =steps_per_epoch= : number of calls to =generate_data= per each epoch
    - =epochs= : number of epoch
    - =validation_data= : initialized with =generate_data= for testing data.
    - =validation_steps= : number of calls to =generate_data= per testing
    - =max_q_size= : number of concurrent generators
    - =workers= : number of threads serving the generators

[fn:5] Details about python generators can be found in official [[https://wiki.python.org/moin/Generators][documentation]].
